{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1"
      ],
      "metadata": {
        "id": "76eJ8KZCdRPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import pi\n",
        "import time\n",
        "from imageio import imread, imwrite\n",
        "from scipy import ndimage"
      ],
      "metadata": {
        "id": "y1we5GqVdRch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5H_TT1xS8ECj"
      },
      "outputs": [],
      "source": [
        "def read(file_name, image_type):\n",
        "    img = cv2.imread(file_name)\n",
        "    if image_type == \"RGB\":\n",
        "        return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    elif image_type == \"HSV\":\n",
        "        return cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "\n",
        "def task_one(img, s, k, alpha):\n",
        "    kernel, blurred, mask, img = sharpen_image_one(img, s, k, alpha)\n",
        "    mask = mask + 128\n",
        "\n",
        "    mat = np.zeros((101, 101))\n",
        "    mat[50, 50] = 255\n",
        "    kernel = cv2.filter2D(mat, ddepth=-1, kernel=kernel)\n",
        "    kernel = cv2.normalize(kernel, 0, 0, 255, cv2.NORM_MINMAX)\n",
        "    cv2.imwrite(\"res01.jpg\", img)\n",
        "\n",
        "\n",
        "def sharpen_image_one(img, s, k, alpha):\n",
        "    img = img.astype('float64')\n",
        "    kernel = get_gaussian_kernel(s, k)\n",
        "    blurred = cv2.filter2D(img, ddepth=-1, kernel=kernel)\n",
        "    mask_1 = img - blurred\n",
        "    mask = alpha * (img - blurred)\n",
        "    img = img + alpha * mask\n",
        "    img[img < 0] = 0\n",
        "    img[img > 255] = 255\n",
        "    return kernel, blurred, mask_1, img\n",
        "\n",
        "\n",
        "def get_gaussian_kernel(s, k):\n",
        "    n = 2 * k + 1\n",
        "    return np.array([[gaussian(k, k, i, j, s) / (2 * pi * s ** 2) for j in range(n)] for i in range(n)])\n",
        "\n",
        "\n",
        "def gaussian(m, n, i, j, sigma):\n",
        "    return np.exp(-((i - m) ** 2 + (j - n) ** 2) / (2 * sigma ** 2))\n",
        "\n",
        "\n",
        "def task_two(img, s, k):\n",
        "    kernel, mask, img = sharpen_image_two(img, s, k)\n",
        "    mask = mask + 128\n",
        "\n",
        "    mat = np.zeros((101, 101))\n",
        "    mat[50, 50] = 255\n",
        "    kernel = cv2.filter2D(mat, ddepth=-1, kernel=kernel)\n",
        "    kernel = cv2.normalize(kernel, 0, 0, 255, cv2.NORM_MINMAX)\n",
        "    cv2.imwrite(\"res02.jpg\", img)\n",
        "\n",
        "\n",
        "def sharpen_image_two(img, s, k):\n",
        "    img = img.astype('float64')\n",
        "    kernel = get_laplacian(s, 9)\n",
        "    mask_1 = cv2.filter2D(img, ddepth=-1, kernel=kernel)\n",
        "    img = img - k * mask_1\n",
        "    img[img < 0] = 0\n",
        "    img[img > 255] = 255\n",
        "    return kernel, mask_1, img\n",
        "\n",
        "\n",
        "def get_laplacian(sigma, n):\n",
        "    kernel = np.array([[laplacian(sigma, (i - (n - 1) / 2), (j - (n - 1) / 2)) for j in range(n)] for i in range(n)])\n",
        "    return kernel\n",
        "\n",
        "\n",
        "def laplacian(sigma, x, y):\n",
        "    laplace = (((x ** 2 + y ** 2) - (2 * sigma ** 2)) * np.exp(-(x ** 2 + y ** 2) / (2 * sigma ** 2))) / (\n",
        "            np.pi * sigma ** 4)\n",
        "    return laplace\n",
        "\n",
        "\n",
        "def get_kernel(rows, cols, s, kernel_type):\n",
        "    m, n = np.floor(rows / 2).astype(int), np.floor(cols / 2).astype(int)\n",
        "    kernel = np.array([[gaussian(m, n, i, j, s) for j in range(cols)] for i in range(rows)])\n",
        "    if kernel_type == \"High_pass\":\n",
        "        return np.ones(kernel.shape) - kernel\n",
        "    else:\n",
        "        return kernel\n",
        "\n",
        "\n",
        "def task_three(img, sigma, alpha):\n",
        "    img_f, high_pass, mask, res_image = sharpen_image_three(img, sigma, alpha)\n",
        "    img_f = np.log(np.abs(img_f))\n",
        "    high_pass = np.abs(high_pass)\n",
        "    mask = np.abs(mask)\n",
        "    img_f = cv2.normalize(img_f, 0, 0, 255, cv2.NORM_MINMAX)\n",
        "    high_pass = cv2.normalize(high_pass, 0, 0, 255, cv2.NORM_MINMAX)\n",
        "    mask = cv2.normalize(mask, 0, 0, 255, cv2.NORM_MINMAX)\n",
        "    cv2.imwrite(\"res03.jpg\", res_image)\n",
        "\n",
        "\n",
        "def sharpen_image_three(img, sigma, alpha):\n",
        "    img = img.astype('float64')\n",
        "    b, g, r = cv2.split(img)\n",
        "    h, w, _ = img.shape\n",
        "    kernel = get_kernel(h, w, sigma, \"High_pass\")\n",
        "    f_r, mask_r, res_r = apply_fourier(r, kernel, alpha)\n",
        "    f_g, mask_g, res_g = apply_fourier(g, kernel, alpha)\n",
        "    f_b, mask_b, res_b = apply_fourier(b, kernel, alpha)\n",
        "    res_f = np.dstack((f_b, f_g, f_r))\n",
        "    res_mask = np.dstack((mask_b, mask_g, mask_r))\n",
        "    res_image = np.dstack((res_b, res_g, res_r))\n",
        "    img[img < 0] = 0\n",
        "    img[img > 255] = 255\n",
        "    return res_f, kernel, res_mask, res_image\n",
        "\n",
        "\n",
        "def apply_fourier(channel, kernel, alpha):\n",
        "    img_f = np.fft.fft2(channel)\n",
        "    img_shifted = np.fft.fftshift(img_f)\n",
        "    mask = 1 + alpha * kernel\n",
        "    res_image = mask * img_shifted\n",
        "    res_image = np.fft.ifftshift(res_image)\n",
        "    res_image = np.fft.ifft2(res_image)\n",
        "    res_image = np.real(res_image)\n",
        "    return img_shifted, mask, res_image\n",
        "\n",
        "\n",
        "def task_four(img, alpha):\n",
        "    img = img.astype('float64')\n",
        "    b, g, r = cv2.split(img)\n",
        "    h, w = r.shape\n",
        "    h2, w2 = h // 2, w // 2\n",
        "    indexes = np.array([[np.abs(i - h2) ** 2 + np.abs(j - w2) ** 2 for j in range(w)] for i in range(h)])\n",
        "    r_mask, r_f, r = apply(r, indexes, alpha)\n",
        "    g_mask, g_f, g = apply(g, indexes, alpha)\n",
        "    b_mask, b_f, b = apply(b, indexes, alpha)\n",
        "    res_mask = np.dstack((b_mask, g_mask, r_mask))\n",
        "    res_mask = np.abs(res_mask)\n",
        "    res_f = np.dstack((b_f, g_f, r_f))\n",
        "    res_f = np.abs(res_f)\n",
        "    res_f = res_f / np.max(res_f) * 255\n",
        "    res_f = 128 + res_f\n",
        "    res_image = np.dstack((b, g, r))\n",
        "    cv2.imwrite(\"res04.jpg\", res_image)\n",
        "\n",
        "\n",
        "def apply(channel, indexes, alpha):\n",
        "    img_f = np.fft.fft2(channel)\n",
        "    img_shifted = np.fft.fftshift(img_f)\n",
        "    mask = (4 * pi ** 2) * indexes * img_shifted\n",
        "    img_back = np.fft.ifftshift(mask)\n",
        "    img_back = np.fft.ifft2(img_back)\n",
        "    res_image = channel + alpha * img_back\n",
        "    res_image = np.abs(res_image)\n",
        "    res_image[res_image < 0] = 0\n",
        "    res_image[res_image > 255] = 255\n",
        "    return mask, img_back, res_image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"image1.jpeg\")\n",
        "\n",
        "start_time = time.time()\n",
        "task_one(image, 1, 2, 2)\n",
        "print(\"execution time:\", time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "task_two(image, 1, 2)\n",
        "print(\"execution time:\", time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "task_three(image, 300, 20)\n",
        "print(\"execution time:\", time.time() - start_time)\n",
        "\n",
        "start_time = time.time()\n",
        "task_four(image, 0.000003)\n",
        "print(\"execution time:\", time.time() - start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz_9f2vTz-E8",
        "outputId": "0c426475-5a9b-4fa7-ab51-3b1b13ccc0a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "execution time: 0.04521536827087402\n",
            "execution time: 0.04064369201660156\n",
            "execution time: 0.8612821102142334\n",
            "execution time: 0.6465568542480469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2"
      ],
      "metadata": {
        "id": "NI-bobISda3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "همانطور که در تصاویر خروجی مشخص است همگی بسته به پارامتر‌های داده شده تصویر خروجی را sharp میکنند اما در تصاویری که از فوریه برای sharp کردن استفاده شده چون تصویر اصلی smooth نبوده و به دلیل ذخیره سازی فشرده شده است و مربع‌هایی در تصویر دیده می‌شود، در تبدیل فوریه این مربعات تشدید شده و باعث ایجاد نویز‌هایی در تصویر شده است. همچنین به لحاظ زمان‌بندی دو روش اول که از تبدیل فوریه استفاده نمی‌کنند سریع‌تر هستند.\n",
        "</div>"
      ],
      "metadata": {
        "id": "bnMFrS3KbDPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = imread('image2.png')"
      ],
      "metadata": {
        "id": "zKZzJ3N2Au_j"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sobel filter"
      ],
      "metadata": {
        "id": "GCpoHaYjEeCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "kernel_y = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
        "\n",
        "sobel_x = ndimage.convolve(img, kernel_x)\n",
        "sobel_y = ndimage.convolve(img, kernel_y)\n",
        "sobel = np.sqrt(sobel_x**2+sobel_y**2)\n",
        "sobel = sobel - np.min(sobel)\n",
        "sobel = sobel / np.max(sobel) * 255\n",
        "\n",
        "imwrite('q5_res01.png', np.uint8(sobel))"
      ],
      "metadata": {
        "id": "vmZcwHPTECxC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gaussian filter"
      ],
      "metadata": {
        "id": "RZxpZ3MuEPhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_kernel(n, sigma):\n",
        "    return [[1/(2*np.pi*sigma**2) * np.exp(-((i-n//2)**2+(j-n//2)**2)/(2*sigma**2)) for j in range(n)] for i in range(n)]\n",
        "\n",
        "kernel = gaussian_kernel(3,1)\n",
        "gaussian = np.uint8(ndimage.convolve(img, kernel))\n",
        "\n",
        "imwrite('q5_res02.png', gaussian)"
      ],
      "metadata": {
        "id": "yFd7VQ5sEJ8l"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Laplacian filter"
      ],
      "metadata": {
        "id": "ip1wCdr1EVWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kernel = np.array([[1, 1, 1], [1, -8, 1], [1, 1, 1]])\n",
        "laplacian = ndimage.convolve(img, kernel)\n",
        "\n",
        "imwrite('q5_res03.png', laplacian)"
      ],
      "metadata": {
        "id": "Ziz71QwaEKhA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frecuency domain"
      ],
      "metadata": {
        "id": "yKuRJxSGIFB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_img = np.fft.fftshift(np.fft.fft2(img))\n",
        "imwrite('q5_res04.png', np.uint8(20*np.log10(np.abs(freq_img))))"
      ],
      "metadata": {
        "id": "u3tuqNuXIAMp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gaussian"
      ],
      "metadata": {
        "id": "Qsaw-kD6IRv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_filter(img, sigma):\n",
        "    x, y = img.shape\n",
        "    i = np.linspace(0, x, x)\n",
        "    j = np.linspace(0, y, y)\n",
        "    filt = np.outer(np.exp(-((i-x//2)**2)/(2*sigma**2)), np.exp(-((j-y//2)**2)/(2*sigma**2)))\n",
        "    return filt/np.max(filt)\n",
        "\n",
        "\n",
        "lp_img_f = freq_img*gaussian_filter(freq_img, 100)\n",
        "imwrite('q5_res05.png', np.uint8(20*np.log10(np.abs(lp_img_f)+1e-3)))\n",
        "\n",
        "hp_img_f = freq_img*(1-gaussian_filter(freq_img, 100))\n",
        "imwrite('q5_res06.png', np.uint8(20*np.log10(np.abs(hp_img_f)+1e-3)))"
      ],
      "metadata": {
        "id": "YgIjVrxfINTZ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lp_img = np.abs(np.fft.ifft2(np.fft.ifftshift(lp_img_f)))\n",
        "hp_img = np.abs(np.fft.ifft2(np.fft.ifftshift(hp_img_f)))\n",
        "\n",
        "lp_img = (lp_img-np.min(lp_img))\n",
        "lp_img = lp_img/(np.max(lp_img)-np.min(lp_img))*255\n",
        "hp_img = (hp_img-np.min(hp_img))\n",
        "hp_img = hp_img/(np.max(hp_img)-np.min(hp_img))*255\n",
        "\n",
        "imwrite('q5_res07.png', np.uint8(lp_img))\n",
        "imwrite('q5_res08.png', np.uint8(hp_img))"
      ],
      "metadata": {
        "id": "y3iXmxePJHXv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Squared"
      ],
      "metadata": {
        "id": "IRQZ-63tJ_jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def squared_filter(img, cutoff):\n",
        "    x, y = img.shape\n",
        "    filt = np.zeros(img.shape)\n",
        "    filt[x//2-cutoff:x//2+cutoff, y//2-cutoff:y//2+cutoff] = 1\n",
        "    return filt/np.max(filt)\n",
        "\n",
        "lp_img_f = freq_img*squared_filter(freq_img, 50)\n",
        "imwrite('q5_res09.png', np.uint8(20*np.log10(np.abs(lp_img_f)+1e-3)))\n",
        "\n",
        "hp_img_f = freq_img*(1-squared_filter(freq_img, 50))\n",
        "imwrite('q5_res10.png', np.uint8(20*np.log10(np.abs(hp_img_f)+1e-3)))"
      ],
      "metadata": {
        "id": "wXxrK4SZJ03t"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lp_img = np.abs(np.fft.ifft2(np.fft.ifftshift(lp_img_f)))\n",
        "hp_img = np.abs(np.fft.ifft2(np.fft.ifftshift(hp_img_f)))\n",
        "\n",
        "lp_img = (lp_img-np.min(lp_img))/(np.max(lp_img)-np.min(lp_img))*255\n",
        "hp_img = (hp_img-np.min(hp_img))/(np.max(hp_img)-np.min(hp_img))*255\n",
        "\n",
        "imwrite('q5_res11.png', np.uint8(lp_img))\n",
        "imwrite('q5_res12.png', np.uint8(hp_img))"
      ],
      "metadata": {
        "id": "UvYGInIDKG3a"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "آ) در خروجی فیلتر گوسی، بخش های دور تصویر که متشکل از نوارهای با فرکانس بالاتر می باشند،\n",
        "تصعیف شده اند.\n",
        "در خروجی فیلتر لاپلاسین، لبه های تصویر  sharp تر شده است همچنین پهنای هر کدام از نوار های دایروی کمتر شده است نکته\n",
        "جالب این است که وسط تصویر به جای دایره سفید در تصویر اصلی، دایره کوچکتری با رنگ سیاه به وجود آمده است.\n",
        "دلیل این اتفاق این است که فیلتر لاپلاسین مشتق دوم را را نمایش می دهد و به دلیل اینکه در وسط تصویر و در بازه مشخصی میزان\n",
        "روشنایی تقریبا ثابت است، مشتقات اول و دوم هردو صفر بوده و به همین دلیل دایره تیره رنگ در وسط صفحه تشکیل شده است.\n",
        "فیلتر سوبل نیز نقش تشخیص لبه در تصویر را انجام می دهد و به همین دلیل در نقاط مرزی لبه های تصویر، خروجی فیلتر سوبل\n",
        "روشنایی بیشتر و در نقاط وسط هر کدام از نوار های تصویر اصلی، خروجی فیلتر سوبل تیره تر می باشد که قابل انتظار است.\n",
        "\n",
        "ب)\n",
        "برای اثبات گوسی بودن تبدیل فوریه فیلتر گوسی از آنجا که فیلتر گوسی جدایی پذیر است، کافیست برای یک فیلتر گوسی یک بعدی این موضوع را\n",
        "اثبات کنیم و در این صورت برای فیلتر گوسی دو بعدی نیز اثبات می شود :\n",
        "</div>\n",
        "\n",
        "$f(u) = \\int \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{x^2}{2\\sigma^2}} e^{-2j\\pi ux} dx$\n",
        "\n",
        "$\\frac{df(u)}{du} = -\\frac{j\\sqrt{2\\pi}}{\\sigma} \\int e^{-2j\\pi ux} x e^{-\\frac{x^2}{2\\sigma^2}} dx = -4\\pi^2\\sigma u f(u)$\n",
        "\n",
        "$\\frac{df(u)}{f(u)} = -2\\pi^2\\sigma^2 du^2 → ln(\\frac{f(u)}{f(0)}) = -2\\pi^2\\sigma^2u^2 → f(u) = f(0)e^{-2\\pi^2\\sigma^2u^2}, f(0) = \\int \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{x^2}{2\\sigma^2}} dx = \\sqrt{2\\pi}\\sigma → \\sqrt{2\\pi} \\sigma e^{2\\pi^2\\sigma^2u^2}$\n",
        "\n",
        "و در نهایت برای حالت دو بعدی خواهیم داشت:\n",
        "\n",
        "$f(u, v) = 2\\pi\\sigma^2 e^{-2\\pi^2\\sigma^2(u^2 + v^2)}$\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "\n",
        " تصویر به دست آمده ناشی از اعمال فیلتر گوسی تفاوتی با تصویر ناشی از\n",
        "کانوالو کردن فیلتر در حوزه زمان که در قسمت قبل به دست آوردیم ندارد. در رابطه با متمم فیلتر گوسی تصویر خروجی در نقاط\n",
        "وسط که فرکانس بالاتری دارد تیره تر شده است و همچنین نوارهای دور صفحه واضح تر و sharp تر شده اند.\n",
        "در مقابل، با اعمال فیلتر مربعی مشاهده می کنیم که باز هم بخش فرکانس بالا حذف شده اما نکته قابل توجه این است که شکل کلی تصویر هم به\n",
        "شکل مربعی در می آید. و باز هم با اعمال متمم مشاهده می شود که بخش های وسط تصویر که دارای فرکانس پایین هستند کاملا از بین رفته اما به دلیل\n",
        "مربعی بودن خود فیلتر بخش های فرکانس بالا نیز دچار تغییراتی می شوند.\n",
        "دلیل به وجود آمدن مربع های کوچک روی تصویر این است که وقتی در حوزه‌ی فرکانس این فیلتر مربعی را در تصویر اعمال می‌کنیم، چون این فیلتر معادل ضرب دو تابع sinc در دو راستای x و y است و چون در حوزه‌ی زمان این فیلتر اعمال می‌شود در برخی نقاط برآیند ضرب این دو تابع در دره و قله ها مثادیر زیاد و کم می‌شود و این باعث به وجود آمدن مربع‌های کوچک در تصاویر می‌شود. مثلا در بخشی از تصویر که کاملا سفید است با جابه‌جا شدن این فیلتر قله‌ها و دره‌ها به صورت متناوب ضرایب زیاد و کم میگیرند.\n",
        "</div>"
      ],
      "metadata": {
        "id": "mQiADE8GLDLM"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}